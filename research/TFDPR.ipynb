{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type dpr. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at firqaaa/indo-dpr-ctx_encoder-multiset-base were not used when initializing DPRContextEncoder: ['encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'embeddings.position_ids', 'encoder.layer.5.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "\n",
    "tokenizer = DPRContextEncoderTokenizer.from_pretrained('firqaaa/indo-dpr-ctx_encoder-multiset-base')\n",
    "model = DPRContextEncoder.from_pretrained('firqaaa/indo-dpr-ctx_encoder-multiset-base')\n",
    "input_ids = tokenizer(\"Siapa nama tokoh utama dalam serial SLAMDunk?\", return_tensors='pt').input_ids\n",
    "embeddings = model(input_ids).pooler_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type dpr. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDPRContextEncoder: ['encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'embeddings.position_ids', 'encoder.layer.5.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.bias']\n",
      "- This IS expected if you are initializing TFDPRContextEncoder from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDPRContextEncoder from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDPRContextEncoder were not initialized from the PyTorch model and are newly initialized: ['bert_model.embeddings.word_embeddings.weight', 'bert_model.embeddings.token_type_embeddings.weight', 'bert_model.embeddings.position_embeddings.weight', 'bert_model.embeddings.LayerNorm.weight', 'bert_model.embeddings.LayerNorm.bias', 'bert_model.encoder.layer.0.attention.self.query.weight', 'bert_model.encoder.layer.0.attention.self.query.bias', 'bert_model.encoder.layer.0.attention.self.key.weight', 'bert_model.encoder.layer.0.attention.self.key.bias', 'bert_model.encoder.layer.0.attention.self.value.weight', 'bert_model.encoder.layer.0.attention.self.value.bias', 'bert_model.encoder.layer.0.attention.output.dense.weight', 'bert_model.encoder.layer.0.attention.output.dense.bias', 'bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.0.intermediate.dense.weight', 'bert_model.encoder.layer.0.intermediate.dense.bias', 'bert_model.encoder.layer.0.output.dense.weight', 'bert_model.encoder.layer.0.output.dense.bias', 'bert_model.encoder.layer.0.output.LayerNorm.weight', 'bert_model.encoder.layer.0.output.LayerNorm.bias', 'bert_model.encoder.layer.1.attention.self.query.weight', 'bert_model.encoder.layer.1.attention.self.query.bias', 'bert_model.encoder.layer.1.attention.self.key.weight', 'bert_model.encoder.layer.1.attention.self.key.bias', 'bert_model.encoder.layer.1.attention.self.value.weight', 'bert_model.encoder.layer.1.attention.self.value.bias', 'bert_model.encoder.layer.1.attention.output.dense.weight', 'bert_model.encoder.layer.1.attention.output.dense.bias', 'bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.1.intermediate.dense.weight', 'bert_model.encoder.layer.1.intermediate.dense.bias', 'bert_model.encoder.layer.1.output.dense.weight', 'bert_model.encoder.layer.1.output.dense.bias', 'bert_model.encoder.layer.1.output.LayerNorm.weight', 'bert_model.encoder.layer.1.output.LayerNorm.bias', 'bert_model.encoder.layer.2.attention.self.query.weight', 'bert_model.encoder.layer.2.attention.self.query.bias', 'bert_model.encoder.layer.2.attention.self.key.weight', 'bert_model.encoder.layer.2.attention.self.key.bias', 'bert_model.encoder.layer.2.attention.self.value.weight', 'bert_model.encoder.layer.2.attention.self.value.bias', 'bert_model.encoder.layer.2.attention.output.dense.weight', 'bert_model.encoder.layer.2.attention.output.dense.bias', 'bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.2.intermediate.dense.weight', 'bert_model.encoder.layer.2.intermediate.dense.bias', 'bert_model.encoder.layer.2.output.dense.weight', 'bert_model.encoder.layer.2.output.dense.bias', 'bert_model.encoder.layer.2.output.LayerNorm.weight', 'bert_model.encoder.layer.2.output.LayerNorm.bias', 'bert_model.encoder.layer.3.attention.self.query.weight', 'bert_model.encoder.layer.3.attention.self.query.bias', 'bert_model.encoder.layer.3.attention.self.key.weight', 'bert_model.encoder.layer.3.attention.self.key.bias', 'bert_model.encoder.layer.3.attention.self.value.weight', 'bert_model.encoder.layer.3.attention.self.value.bias', 'bert_model.encoder.layer.3.attention.output.dense.weight', 'bert_model.encoder.layer.3.attention.output.dense.bias', 'bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.3.intermediate.dense.weight', 'bert_model.encoder.layer.3.intermediate.dense.bias', 'bert_model.encoder.layer.3.output.dense.weight', 'bert_model.encoder.layer.3.output.dense.bias', 'bert_model.encoder.layer.3.output.LayerNorm.weight', 'bert_model.encoder.layer.3.output.LayerNorm.bias', 'bert_model.encoder.layer.4.attention.self.query.weight', 'bert_model.encoder.layer.4.attention.self.query.bias', 'bert_model.encoder.layer.4.attention.self.key.weight', 'bert_model.encoder.layer.4.attention.self.key.bias', 'bert_model.encoder.layer.4.attention.self.value.weight', 'bert_model.encoder.layer.4.attention.self.value.bias', 'bert_model.encoder.layer.4.attention.output.dense.weight', 'bert_model.encoder.layer.4.attention.output.dense.bias', 'bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.4.intermediate.dense.weight', 'bert_model.encoder.layer.4.intermediate.dense.bias', 'bert_model.encoder.layer.4.output.dense.weight', 'bert_model.encoder.layer.4.output.dense.bias', 'bert_model.encoder.layer.4.output.LayerNorm.weight', 'bert_model.encoder.layer.4.output.LayerNorm.bias', 'bert_model.encoder.layer.5.attention.self.query.weight', 'bert_model.encoder.layer.5.attention.self.query.bias', 'bert_model.encoder.layer.5.attention.self.key.weight', 'bert_model.encoder.layer.5.attention.self.key.bias', 'bert_model.encoder.layer.5.attention.self.value.weight', 'bert_model.encoder.layer.5.attention.self.value.bias', 'bert_model.encoder.layer.5.attention.output.dense.weight', 'bert_model.encoder.layer.5.attention.output.dense.bias', 'bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.5.intermediate.dense.weight', 'bert_model.encoder.layer.5.intermediate.dense.bias', 'bert_model.encoder.layer.5.output.dense.weight', 'bert_model.encoder.layer.5.output.dense.bias', 'bert_model.encoder.layer.5.output.LayerNorm.weight', 'bert_model.encoder.layer.5.output.LayerNorm.bias', 'bert_model.encoder.layer.6.attention.self.query.weight', 'bert_model.encoder.layer.6.attention.self.query.bias', 'bert_model.encoder.layer.6.attention.self.key.weight', 'bert_model.encoder.layer.6.attention.self.key.bias', 'bert_model.encoder.layer.6.attention.self.value.weight', 'bert_model.encoder.layer.6.attention.self.value.bias', 'bert_model.encoder.layer.6.attention.output.dense.weight', 'bert_model.encoder.layer.6.attention.output.dense.bias', 'bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.6.intermediate.dense.weight', 'bert_model.encoder.layer.6.intermediate.dense.bias', 'bert_model.encoder.layer.6.output.dense.weight', 'bert_model.encoder.layer.6.output.dense.bias', 'bert_model.encoder.layer.6.output.LayerNorm.weight', 'bert_model.encoder.layer.6.output.LayerNorm.bias', 'bert_model.encoder.layer.7.attention.self.query.weight', 'bert_model.encoder.layer.7.attention.self.query.bias', 'bert_model.encoder.layer.7.attention.self.key.weight', 'bert_model.encoder.layer.7.attention.self.key.bias', 'bert_model.encoder.layer.7.attention.self.value.weight', 'bert_model.encoder.layer.7.attention.self.value.bias', 'bert_model.encoder.layer.7.attention.output.dense.weight', 'bert_model.encoder.layer.7.attention.output.dense.bias', 'bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.7.intermediate.dense.weight', 'bert_model.encoder.layer.7.intermediate.dense.bias', 'bert_model.encoder.layer.7.output.dense.weight', 'bert_model.encoder.layer.7.output.dense.bias', 'bert_model.encoder.layer.7.output.LayerNorm.weight', 'bert_model.encoder.layer.7.output.LayerNorm.bias', 'bert_model.encoder.layer.8.attention.self.query.weight', 'bert_model.encoder.layer.8.attention.self.query.bias', 'bert_model.encoder.layer.8.attention.self.key.weight', 'bert_model.encoder.layer.8.attention.self.key.bias', 'bert_model.encoder.layer.8.attention.self.value.weight', 'bert_model.encoder.layer.8.attention.self.value.bias', 'bert_model.encoder.layer.8.attention.output.dense.weight', 'bert_model.encoder.layer.8.attention.output.dense.bias', 'bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.8.intermediate.dense.weight', 'bert_model.encoder.layer.8.intermediate.dense.bias', 'bert_model.encoder.layer.8.output.dense.weight', 'bert_model.encoder.layer.8.output.dense.bias', 'bert_model.encoder.layer.8.output.LayerNorm.weight', 'bert_model.encoder.layer.8.output.LayerNorm.bias', 'bert_model.encoder.layer.9.attention.self.query.weight', 'bert_model.encoder.layer.9.attention.self.query.bias', 'bert_model.encoder.layer.9.attention.self.key.weight', 'bert_model.encoder.layer.9.attention.self.key.bias', 'bert_model.encoder.layer.9.attention.self.value.weight', 'bert_model.encoder.layer.9.attention.self.value.bias', 'bert_model.encoder.layer.9.attention.output.dense.weight', 'bert_model.encoder.layer.9.attention.output.dense.bias', 'bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.9.intermediate.dense.weight', 'bert_model.encoder.layer.9.intermediate.dense.bias', 'bert_model.encoder.layer.9.output.dense.weight', 'bert_model.encoder.layer.9.output.dense.bias', 'bert_model.encoder.layer.9.output.LayerNorm.weight', 'bert_model.encoder.layer.9.output.LayerNorm.bias', 'bert_model.encoder.layer.10.attention.self.query.weight', 'bert_model.encoder.layer.10.attention.self.query.bias', 'bert_model.encoder.layer.10.attention.self.key.weight', 'bert_model.encoder.layer.10.attention.self.key.bias', 'bert_model.encoder.layer.10.attention.self.value.weight', 'bert_model.encoder.layer.10.attention.self.value.bias', 'bert_model.encoder.layer.10.attention.output.dense.weight', 'bert_model.encoder.layer.10.attention.output.dense.bias', 'bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.10.intermediate.dense.weight', 'bert_model.encoder.layer.10.intermediate.dense.bias', 'bert_model.encoder.layer.10.output.dense.weight', 'bert_model.encoder.layer.10.output.dense.bias', 'bert_model.encoder.layer.10.output.LayerNorm.weight', 'bert_model.encoder.layer.10.output.LayerNorm.bias', 'bert_model.encoder.layer.11.attention.self.query.weight', 'bert_model.encoder.layer.11.attention.self.query.bias', 'bert_model.encoder.layer.11.attention.self.key.weight', 'bert_model.encoder.layer.11.attention.self.key.bias', 'bert_model.encoder.layer.11.attention.self.value.weight', 'bert_model.encoder.layer.11.attention.self.value.bias', 'bert_model.encoder.layer.11.attention.output.dense.weight', 'bert_model.encoder.layer.11.attention.output.dense.bias', 'bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.11.intermediate.dense.weight', 'bert_model.encoder.layer.11.intermediate.dense.bias', 'bert_model.encoder.layer.11.output.dense.weight', 'bert_model.encoder.layer.11.output.dense.bias', 'bert_model.encoder.layer.11.output.LayerNorm.weight', 'bert_model.encoder.layer.11.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDPRContextEncoder, DPRContextEncoderTokenizer\n",
    "\n",
    "tokenizer = DPRContextEncoderTokenizer.from_pretrained('firqaaa/indo-dpr-ctx_encoder-multiset-base')\n",
    "model_2 = TFDPRContextEncoder.from_pretrained('firqaaa/indo-dpr-ctx_encoder-multiset-base', from_pt=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_1 = tokenizer(\"Siapa nama tokoh utama dalam serial SLAMDunk?\", return_tensors='pt').input_ids\n",
    "\n",
    "input_ids_2 = tokenizer(\"Siapa nama tokoh utama dalam serial SLAMDunk?\", return_tensors='tf').input_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFDPRContextEncoderOutput(pooler_output=<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       "array([[-2.63230056e-01, -5.92078567e-01, -1.43178403e+00,\n",
       "         1.61296770e-01,  1.17975771e+00, -3.41124982e-01,\n",
       "        -1.04890013e+00, -1.31606507e+00, -1.04206419e+00,\n",
       "        -4.05652970e-02, -2.10651588e+00,  1.49172556e+00,\n",
       "        -1.61426258e+00, -1.11418533e+00, -8.37270319e-02,\n",
       "         1.11015248e+00,  8.74406576e-01, -6.25697970e-01,\n",
       "        -1.08078659e+00,  4.35445346e-02, -7.63017163e-02,\n",
       "        -7.46722892e-02,  3.70423883e-01,  6.56409934e-02,\n",
       "        -4.34281528e-01,  2.46347117e+00,  1.00180745e+00,\n",
       "         5.86994171e-01, -6.21517785e-02, -2.71239191e-01,\n",
       "         1.33950460e+00,  1.05612862e+00,  7.64263093e-01,\n",
       "         1.77435398e+00,  2.91733116e-01,  8.46781671e-01,\n",
       "         9.69883442e-01,  3.43588382e-01, -1.22348440e+00,\n",
       "         5.53927720e-01,  7.23077118e-01,  6.11035585e-01,\n",
       "         3.47085565e-01, -5.09071350e-01,  4.56112325e-01,\n",
       "        -1.04976967e-01, -1.72839403e+00,  8.48273814e-01,\n",
       "         1.32420182e+00,  7.73369253e-01,  3.37440103e-01,\n",
       "         1.69375092e-01, -5.61622858e-01, -1.14663422e+00,\n",
       "         2.56015003e-01,  7.20742643e-01,  1.02705216e+00,\n",
       "         1.82636476e+00, -1.15257275e+00, -2.63003469e+00,\n",
       "         1.14984763e+00,  2.06386948e+00, -4.87248600e-01,\n",
       "         2.34452200e+00, -3.56397778e-01, -1.70996845e+00,\n",
       "        -5.61339676e-01,  4.63444889e-02, -1.14722657e+00,\n",
       "         6.68982685e-01, -1.26860607e+00, -1.20302200e+00,\n",
       "         1.84207296e+00, -9.38598990e-01,  2.23808551e+00,\n",
       "        -4.88867849e-01, -6.51074946e-01, -6.05603755e-01,\n",
       "        -6.03486955e-01, -2.21259855e-02,  2.70229250e-01,\n",
       "        -1.07846653e+00, -8.10118198e-01, -8.22233319e-01,\n",
       "        -7.68965840e-01,  1.18336535e+00, -8.00614595e-01,\n",
       "        -8.51360202e-01, -6.32109880e-01,  1.08245385e+00,\n",
       "        -6.08339846e-01, -4.14634615e-01,  1.79446954e-02,\n",
       "        -5.87855399e-01,  1.21717906e+00,  6.21180117e-01,\n",
       "         5.33858836e-02,  4.32458147e-02,  5.35199225e-01,\n",
       "        -4.97524440e-02,  1.19615883e-01, -7.60441720e-02,\n",
       "        -1.44043529e+00,  1.05524674e-01, -1.76989400e+00,\n",
       "        -1.02608895e+00,  7.77306616e-01,  1.29567683e+00,\n",
       "         7.52159357e-01,  1.93979466e+00,  5.50597131e-01,\n",
       "        -4.87468868e-01, -2.36014277e-01,  1.39266539e+00,\n",
       "         1.13704853e-01,  3.98310125e-01, -6.63382292e-01,\n",
       "         1.31704879e+00,  1.80176187e+00, -8.04201603e-01,\n",
       "         2.02264404e+00, -5.99519372e-01, -1.35220826e-01,\n",
       "         1.86059326e-01,  9.53064442e-01,  8.32698703e-01,\n",
       "         1.37094963e+00,  6.35123432e-01,  1.75668132e+00,\n",
       "        -4.22300458e-01, -3.84952798e-02, -2.05770135e+00,\n",
       "         2.25153995e+00,  1.64262199e+00, -1.23557615e+00,\n",
       "        -6.94467127e-02,  1.14451337e+00, -1.40784717e+00,\n",
       "         1.05469787e+00, -1.12660921e+00,  2.88987726e-01,\n",
       "         1.44159663e+00,  2.17127860e-01, -2.35145897e-01,\n",
       "         7.61330307e-01, -8.79494190e-01, -1.17987120e+00,\n",
       "        -3.38529493e-03, -4.28391218e-01,  2.88130678e-02,\n",
       "        -4.97794062e-01,  1.33945274e+00, -2.27538645e-01,\n",
       "         3.39792252e-01, -6.88314021e-01, -7.36868680e-01,\n",
       "        -3.58260095e-01,  7.07569003e-01, -2.31281921e-01,\n",
       "         2.07871389e+00, -8.80549490e-01, -6.88554823e-01,\n",
       "         7.52973855e-01,  9.48411524e-01,  2.48596117e-01,\n",
       "        -6.24419868e-01,  1.65979743e+00,  1.52892637e+00,\n",
       "        -2.76507831e+00,  1.32320487e+00,  7.33894706e-01,\n",
       "        -1.76060390e+00,  2.89416885e+00,  1.01303327e+00,\n",
       "        -4.75387782e-01, -1.57737529e+00, -1.33400679e+00,\n",
       "         1.04195082e+00, -7.76475549e-01,  1.66105002e-01,\n",
       "         8.51388797e-02, -5.28067768e-01, -8.59272122e-01,\n",
       "        -1.56765914e+00,  3.07956308e-01,  9.48535144e-01,\n",
       "         1.64324963e+00,  1.69216859e+00, -3.83948624e-01,\n",
       "        -7.91552007e-01,  6.38807893e-01, -1.55076206e-01,\n",
       "         4.11215872e-01, -3.26240450e-01, -2.93137908e-01,\n",
       "         7.97275454e-02, -6.78620756e-01,  4.78813469e-01,\n",
       "        -7.43127018e-02, -7.69602060e-01, -1.99769642e-02,\n",
       "        -3.90817553e-01,  1.76465547e+00,  2.00744480e-01,\n",
       "         9.58259311e-03,  1.11047816e+00,  1.43637970e-01,\n",
       "         2.88995564e-01,  4.79530782e-01,  1.02186954e+00,\n",
       "        -5.24451673e-01, -3.09965998e-01, -1.37842402e-01,\n",
       "         5.53601623e-01, -1.03005397e+00,  2.48273540e+00,\n",
       "        -1.10984027e+00, -1.45459488e-01,  1.33011079e+00,\n",
       "         9.71772492e-01, -2.31536716e-01, -1.83243051e-01,\n",
       "         8.65194201e-01, -1.61093622e-01,  1.80369556e+00,\n",
       "        -3.54576975e-01, -1.38294232e+00,  5.72609365e-01,\n",
       "         2.32129335e-01, -2.66825199e-01, -8.71517718e-01,\n",
       "        -5.42223752e-01, -2.78822243e-01,  4.57088619e-01,\n",
       "        -1.96794975e+00, -7.41576999e-02,  2.74529845e-01,\n",
       "         1.01020701e-01,  1.56435955e+00,  1.11685127e-01,\n",
       "         1.15901482e+00,  3.20650935e-01, -6.77016377e-01,\n",
       "         5.69577754e-01,  1.91031528e+00,  1.82942286e-01,\n",
       "        -4.00298059e-01, -5.54937273e-02,  9.72364008e-01,\n",
       "         5.07142246e-01,  7.31805623e-01, -1.36280072e+00,\n",
       "        -2.52614975e-01, -9.68576789e-01, -1.47939289e+00,\n",
       "        -9.63856995e-01,  1.14905834e+00,  8.54288816e-01,\n",
       "         1.77986041e-01, -1.13050401e+00,  2.29182616e-01,\n",
       "         1.01039469e+00,  1.62286758e-01,  4.39068884e-01,\n",
       "        -1.15826368e+00, -5.76870978e-01,  3.70224833e-01,\n",
       "         3.36647004e-01, -2.31355667e+00,  1.50615603e-01,\n",
       "         4.91596282e-01, -1.09295703e-01,  2.36366704e-01,\n",
       "         4.50941294e-01, -4.66552705e-01, -2.26787686e+00,\n",
       "         5.84590316e-01, -1.44340479e+00, -1.09759653e+00,\n",
       "         7.64275908e-01,  5.08020937e-01, -4.00523916e-02,\n",
       "         2.27452591e-02,  8.80998850e-01, -3.21168564e-02,\n",
       "         2.54857212e-01,  2.00757074e+00,  5.52227674e-03,\n",
       "        -1.46061277e+00, -4.07955348e-01, -1.63230336e+00,\n",
       "        -4.92014647e-01,  6.85091078e-01, -5.24126828e-01,\n",
       "        -6.48130357e-01,  1.27968013e+00,  4.74081129e-01,\n",
       "        -2.92987752e+00,  1.54947102e+00,  1.86690485e+00,\n",
       "         4.46311086e-01,  3.24948025e+00,  2.08484843e-01,\n",
       "         2.04464650e+00, -2.16017589e-01,  5.86016119e-01,\n",
       "         7.67772615e-01,  8.98045599e-01,  1.27740547e-01,\n",
       "         2.54185677e-01,  6.71201199e-02, -7.34535933e-01,\n",
       "        -4.33763951e-01, -2.86086828e-01, -1.42308331e+00,\n",
       "         9.77005899e-01,  5.32952368e-01,  3.16505253e-01,\n",
       "        -1.69746995e+00, -2.04144955e-01, -2.66657054e-01,\n",
       "        -1.18105495e+00,  1.44573140e+00,  2.99397439e-01,\n",
       "         9.01287675e-01, -9.37818468e-01, -1.31138587e+00,\n",
       "        -3.28768253e-01, -6.47295773e-01, -3.90221804e-01,\n",
       "        -3.58515292e-01, -2.89497048e-01,  1.92832673e+00,\n",
       "        -8.56607258e-01,  1.51428556e+00, -7.49063075e-01,\n",
       "        -1.10038257e+00,  3.07237804e-01,  1.08400595e+00,\n",
       "         1.21178376e-02, -8.41568410e-03,  1.58020067e+00,\n",
       "         7.81525314e-01,  3.84853333e-01,  1.01519835e+00,\n",
       "        -7.00466692e-01, -8.15350533e-01,  1.33832538e+00,\n",
       "         4.38574590e-02, -3.63277614e-01, -1.27977085e+00,\n",
       "         3.01063359e-01,  1.86847734e+00, -3.31530601e-01,\n",
       "         1.03378713e+00,  2.48691663e-01,  1.30680895e+00,\n",
       "        -1.41360652e+00, -7.33625948e-01,  1.23426206e-01,\n",
       "         1.52886003e-01, -1.79816234e+00,  1.37015212e+00,\n",
       "        -2.26974308e-01, -1.09640968e+00, -1.98700130e-01,\n",
       "         4.00923163e-01,  1.19278634e+00,  8.20409179e-01,\n",
       "        -1.23285428e-01, -1.28108954e+00,  8.57884645e-01,\n",
       "        -2.25387907e+00, -2.14634705e+00, -1.49884963e+00,\n",
       "        -3.00958067e-01,  4.72343802e-01, -4.07701403e-01,\n",
       "         1.43751740e-01,  4.85374257e-02, -7.97420919e-01,\n",
       "        -4.43556517e-01,  5.65391660e-01,  9.72858667e-01,\n",
       "        -1.05088151e+00,  3.98958862e-01,  8.89824390e-01,\n",
       "        -1.00710702e+00,  1.05229843e+00, -6.53789282e-01,\n",
       "        -9.28344369e-01, -3.70403051e-01,  2.18646240e+00,\n",
       "         1.36313403e+00,  4.80760366e-01, -8.30948293e-01,\n",
       "        -1.05871305e-01, -3.08738589e-01,  1.01835799e+00,\n",
       "        -1.00943516e-03, -2.03737426e+00,  5.34752846e-01,\n",
       "         8.19937289e-01, -9.70169127e-01, -4.19507116e-01,\n",
       "        -1.09858489e+00, -1.17079854e+00,  1.36452472e+00,\n",
       "        -4.37812179e-01, -2.86578989e+00, -7.83221647e-02,\n",
       "         7.33269632e-01, -1.79541886e+00, -3.33632141e-01,\n",
       "         1.59570885e+00,  2.57831216e-01,  2.12109044e-01,\n",
       "        -2.63965447e-02,  1.40601146e+00,  3.88155252e-01,\n",
       "        -1.43283874e-01,  1.49033165e+00, -1.70419657e+00,\n",
       "        -1.17111015e+00, -7.74905741e-01, -3.23286772e-01,\n",
       "         6.02892101e-01,  9.53642368e-01, -3.81508656e-02,\n",
       "         1.02270889e+00,  1.01349342e+00, -1.11343956e+00,\n",
       "        -3.31228018e-01,  8.11907768e-01, -1.48142099e-01,\n",
       "        -3.81839484e-01,  5.58554232e-01,  8.41773987e-01,\n",
       "        -1.88437569e+00,  2.44550124e-01,  8.96427557e-02,\n",
       "        -1.40465879e+00,  1.40117303e-01,  8.94697607e-01,\n",
       "         1.29546475e+00,  6.80772960e-01,  1.28408253e+00,\n",
       "        -6.58599854e-01,  4.82023418e-01,  4.01626825e-01,\n",
       "         7.48170972e-01, -1.52421784e+00, -2.40499806e+00,\n",
       "        -1.36462584e-01, -6.82021320e-01,  8.21721137e-01,\n",
       "        -8.19224298e-01, -1.61430016e-01, -1.26293206e+00,\n",
       "        -4.35960233e-01,  1.25414252e+00, -2.53057126e-02,\n",
       "        -2.51374698e+00, -1.94148982e+00, -7.53701031e-01,\n",
       "        -1.41547009e-01,  5.95505416e-01, -1.51336932e+00,\n",
       "         9.85281169e-01,  1.46299839e+00, -6.91942632e-01,\n",
       "         1.61283180e-01, -1.65488005e+00,  6.75760508e-01,\n",
       "         1.66245669e-01, -2.95621455e-01, -5.62258184e-01,\n",
       "        -1.32990658e-01, -1.88300228e+00,  9.05148268e-01,\n",
       "         6.99052811e-02,  6.90980971e-01, -1.53083801e-01,\n",
       "        -1.44477105e+00, -2.51504958e-01, -8.67143989e-01,\n",
       "         1.19947183e+00,  3.92693728e-02,  1.32703915e-01,\n",
       "         4.62722242e-01, -1.65000653e+00, -2.53301096e+00,\n",
       "         3.02386254e-01, -4.95100737e-01, -4.30927068e-01,\n",
       "         5.67511857e-01, -6.02808654e-01, -1.53827405e+00,\n",
       "        -2.01672778e-01,  7.70416021e-01, -2.75711775e-01,\n",
       "         9.65821862e-01, -6.35607362e-01, -3.00423801e-01,\n",
       "        -1.85996962e+00,  1.01076686e+00, -7.49232471e-01,\n",
       "         2.80815601e-01, -7.22675100e-02, -1.02026665e+00,\n",
       "         6.27117217e-01,  4.22289282e-01,  3.98422867e-01,\n",
       "         1.73140347e+00, -7.38188177e-02,  1.23891819e+00,\n",
       "        -1.80692732e+00,  2.54003525e+00,  1.81358472e-01,\n",
       "         8.28034401e-01,  1.22527397e+00, -5.15603781e-01,\n",
       "        -1.96038894e-02,  1.04881600e-01,  1.35091674e+00,\n",
       "        -7.37829924e-01, -2.27126670e+00, -1.25644219e+00,\n",
       "        -1.05473375e+00,  1.84783190e-01, -1.48414779e+00,\n",
       "         8.13030779e-01,  1.59784377e+00,  2.22190708e-01,\n",
       "         7.49862194e-01, -3.97134632e-01,  5.73681831e-01,\n",
       "         4.00546312e-01,  2.48380050e-01,  4.18771394e-02,\n",
       "         2.45309487e-01, -2.11718202e+00, -3.29507202e-01,\n",
       "        -1.40295759e-01, -4.85033929e-01, -9.64162946e-01,\n",
       "         8.91195238e-01,  1.27608109e+00, -7.12077022e-01,\n",
       "         8.82051885e-01,  1.81586635e+00, -1.73036802e+00,\n",
       "         5.25169551e-01, -1.47456884e+00,  3.97324145e-01,\n",
       "        -7.43637025e-01, -1.20728683e+00,  1.76649702e+00,\n",
       "         3.74870121e-01,  5.21240942e-02,  3.34630191e-01,\n",
       "         7.10350215e-01,  3.38030308e-01,  8.77771080e-01,\n",
       "        -3.25499713e-01, -1.92982599e-01,  4.20623925e-03,\n",
       "        -1.32364607e+00, -4.47233170e-01, -1.54493153e+00,\n",
       "         8.75721753e-01, -7.33658433e-01,  4.53688860e-01,\n",
       "         1.38001883e+00,  1.00471273e-01,  6.26644194e-01,\n",
       "        -2.70117569e+00, -1.91503167e-01, -5.71177781e-01,\n",
       "        -8.34104180e-01, -1.01795644e-01, -2.91910991e-02,\n",
       "        -1.14189339e+00, -1.73275769e-01, -1.23671882e-01,\n",
       "         1.31593359e+00,  5.94640076e-01,  2.01456428e-01,\n",
       "         1.42787397e+00, -4.50339258e-01, -4.49116170e-01,\n",
       "         1.01195328e-01, -1.27535653e+00, -1.81070840e+00,\n",
       "        -1.01511335e+00,  1.72182703e+00, -4.73795049e-02,\n",
       "         1.98251441e-01, -1.45207688e-01,  6.51126504e-01,\n",
       "        -1.20019758e+00,  3.48198228e-02,  4.14319992e-01,\n",
       "        -1.64357281e+00, -3.77988726e-01,  2.63584304e+00,\n",
       "         1.03684485e+00, -4.50423621e-02, -1.83554754e-01,\n",
       "         6.56098187e-01, -9.37751412e-01, -8.37022141e-02,\n",
       "         1.39197692e-01, -1.19623291e+00, -3.75923127e-01,\n",
       "        -5.68692863e-01, -9.76990044e-01, -6.61268055e-01,\n",
       "         1.16618371e+00, -3.85501087e-01, -5.38047075e-01,\n",
       "         3.36588353e-01, -5.14382064e-01, -1.12952018e+00,\n",
       "        -2.42278719e+00,  1.20748818e+00, -1.52979925e-01,\n",
       "        -1.40347290e+00,  4.43153709e-01, -7.30358288e-02,\n",
       "         2.44889408e-01,  9.38362956e-01, -1.15840805e+00,\n",
       "         8.62153292e-01, -1.80915594e-01, -1.63914204e+00,\n",
       "        -5.23956180e-01, -2.13882364e-02,  8.57860386e-01,\n",
       "        -5.63346565e-01, -8.77442718e-01,  1.60082769e+00,\n",
       "         5.79290569e-01,  1.76087961e-01,  1.26409566e+00,\n",
       "        -1.17667222e+00,  1.39204592e-01, -1.00946510e+00,\n",
       "        -8.42053115e-01, -1.77271709e-01,  1.14414501e+00,\n",
       "         2.74184421e-02,  3.59676540e-01, -2.06788063e+00,\n",
       "         2.71828651e-01, -8.74401033e-02,  4.44565922e-01,\n",
       "         4.22288537e-01,  3.57586831e-01, -7.01288521e-01,\n",
       "        -3.83122861e-01,  6.88439906e-02, -1.02427626e+00,\n",
       "        -5.09210765e-01, -6.15047812e-01,  2.91446716e-01,\n",
       "         1.25542223e-01, -6.19644046e-01, -1.60391793e-01,\n",
       "         1.00354457e+00, -6.68450236e-01, -8.88299108e-01,\n",
       "        -6.76191747e-02,  1.56931788e-01, -6.98220909e-01,\n",
       "        -1.27101028e+00, -8.95198211e-02, -1.85357824e-01,\n",
       "        -9.62288022e-01,  1.21507898e-01, -5.55563867e-01,\n",
       "        -3.56170595e-01, -4.72306520e-01, -7.60987937e-01,\n",
       "         2.64721662e-01,  5.23693860e-01,  1.69443324e-01,\n",
       "        -6.58818543e-01, -1.15982926e+00,  6.47960663e-01,\n",
       "         5.72399735e-01, -1.65650368e+00, -3.35460067e-01,\n",
       "         1.06251919e+00,  4.76583600e-01, -3.32324564e-01,\n",
       "         3.56682837e-01, -1.80625761e+00,  5.22283494e-01,\n",
       "        -1.68854201e+00, -6.69822276e-01,  6.62520707e-01,\n",
       "        -7.61220992e-01,  2.35317171e-01,  6.64959610e-01,\n",
       "        -5.97401142e-01,  1.05841124e+00, -3.37751031e-01,\n",
       "         5.81229746e-01, -4.80928838e-01, -1.23476982e-01,\n",
       "         1.46639132e+00, -1.55594134e+00,  6.65814519e-01,\n",
       "         1.83438754e+00,  1.37907207e+00, -5.86430550e-01,\n",
       "         1.11599815e+00,  6.38145983e-01,  1.20190948e-01,\n",
       "         1.04373586e+00,  5.38716376e-01,  1.57294774e+00,\n",
       "         9.87847865e-01, -1.28242850e+00,  1.18932974e+00,\n",
       "        -1.75437605e+00,  1.34456503e+00,  2.11447191e+00,\n",
       "         8.23458850e-01,  3.27241898e-01, -7.81716645e-01,\n",
       "         1.04410839e+00, -7.17208982e-01,  5.92656493e-01,\n",
       "        -6.81984603e-01, -5.92656076e-01,  2.18315929e-01,\n",
       "         3.11963797e-01, -6.68254614e-01, -7.42233157e-01,\n",
       "        -6.07859313e-01,  8.35587382e-01,  2.69045264e-01,\n",
       "         2.99664795e-01, -8.79730165e-01, -1.76184773e-01,\n",
       "         9.90906656e-02, -1.29426742e+00,  2.04534486e-01,\n",
       "        -9.90900338e-01,  1.44174695e+00, -4.15260047e-01,\n",
       "        -1.63841832e+00,  2.18640536e-01, -2.76033074e-01,\n",
       "         3.48497629e+00, -3.55657279e-01,  6.91475719e-02,\n",
       "         1.85171342e+00,  5.80976903e-01,  6.23793565e-02,\n",
       "         1.27460635e+00, -6.73699021e-01,  8.02537322e-01,\n",
       "         7.26972818e-02,  9.77060735e-01, -7.07928061e-01]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2(input_ids_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPRContextEncoderOutput(pooler_output=tensor([[-3.2696e-01, -5.6974e-01, -4.5847e-01,  9.6767e-01, -4.9304e-03,\n",
       "         -1.1595e+00,  1.1894e-01, -5.1472e-01,  9.5948e-01,  2.8087e-01,\n",
       "         -1.3852e-01,  8.9830e-01, -2.7165e-01,  9.6475e-02,  1.5831e+00,\n",
       "          1.9040e+00,  5.4903e-01, -2.1867e+00, -1.5420e+00,  1.0838e+00,\n",
       "         -1.4174e+00, -4.0389e-01,  7.8004e-01, -2.5144e-01, -1.1143e+00,\n",
       "         -3.2405e-01,  8.5486e-01, -1.0413e+00, -1.8865e+00, -4.4373e-01,\n",
       "          1.4159e+00, -5.5241e-01,  6.5219e-01,  5.1642e-01, -1.3179e+00,\n",
       "          1.3497e+00,  9.4761e-01,  1.5093e+00, -4.1272e-01,  1.9850e+00,\n",
       "          6.1105e-02, -1.2626e+00,  4.0302e+00,  1.3983e-01, -1.0798e+00,\n",
       "         -7.6212e-01, -1.5610e+00,  4.5763e-01, -1.5821e+00,  5.5121e-01,\n",
       "          1.0576e+00,  1.7860e+00,  4.8908e-01, -8.2481e-01,  3.7022e-01,\n",
       "         -2.7085e+00, -1.0307e+00, -2.5806e-01, -1.3543e+00,  1.5349e+00,\n",
       "         -1.5350e+00, -1.0542e+00, -2.3433e+00, -4.0866e-01,  2.6248e+00,\n",
       "          6.2799e-01,  3.8636e-01,  4.3900e-01, -4.2194e-01,  8.2950e-01,\n",
       "          3.1428e+00,  2.4812e-01, -1.4398e+00, -3.6103e-01,  4.8495e-01,\n",
       "          6.2329e-01, -3.8691e-01, -7.8631e-01,  1.0419e+00,  3.8616e-01,\n",
       "          1.1293e+00, -9.3283e-01, -6.6977e-02,  1.2447e+00,  1.6043e+00,\n",
       "         -1.0743e+00,  5.9999e-01,  2.6282e-01, -2.9620e-01,  1.3655e+00,\n",
       "          1.2124e-01, -1.3389e+00,  1.8785e-01, -4.3219e-01,  6.3376e-01,\n",
       "          1.8125e+00, -1.2504e+00, -3.6521e-01,  4.3969e-02,  6.7692e-02,\n",
       "          6.5320e-01, -6.3684e-01,  9.6467e-01,  5.0669e-01, -2.6597e-01,\n",
       "          1.0177e+00, -5.8824e-01,  3.0748e-01,  5.6676e-01,  8.0982e-01,\n",
       "          2.7985e-01, -1.1113e+00, -4.8487e-01,  3.2955e-01,  6.1672e-01,\n",
       "         -9.8775e-01,  1.5281e+00,  7.1089e-01, -5.1624e-02, -6.2083e-01,\n",
       "          2.0967e-01,  3.0659e-01, -1.4614e-01,  1.1322e+00,  1.3907e-01,\n",
       "          2.0601e+00,  4.4608e-01, -5.8964e-01,  9.9296e-01,  1.7525e-01,\n",
       "         -4.6067e-01,  8.5196e-01,  3.8452e-01,  1.0842e+00,  5.9847e-01,\n",
       "          4.1727e-01,  6.4528e-01, -1.4281e+00, -4.5734e-01, -3.6139e-01,\n",
       "         -9.9121e-01,  3.1748e-01,  3.7840e-01,  6.9650e-01, -2.7967e-01,\n",
       "         -1.4895e+00,  5.8624e-01, -4.0422e-01,  5.9428e-01, -7.9971e-01,\n",
       "          3.7403e-01, -2.9397e-01, -8.1439e-01,  3.3427e-01,  7.1863e-01,\n",
       "          1.5294e-01, -2.3714e-01,  1.0715e+00,  1.4993e+00,  2.8081e-02,\n",
       "         -8.0097e-01,  6.4845e-01,  7.6514e-01, -3.9957e-02,  4.1982e-01,\n",
       "          1.6281e+00, -3.3146e-01,  2.1901e-01,  3.5459e-02,  8.0504e-01,\n",
       "          5.2110e-01,  1.1191e+00,  5.6755e-01,  2.5248e-01,  1.3633e-02,\n",
       "         -4.7692e-01,  1.8845e-01, -6.2465e-01,  5.4292e-01,  4.1095e-01,\n",
       "          4.4206e-03,  2.8133e-01, -1.0322e+00, -4.2597e-01, -7.4914e-01,\n",
       "          1.1277e+00,  9.7627e-01,  5.6745e-01,  3.5404e-01,  2.0562e-01,\n",
       "          1.1742e+00,  1.0226e+00, -1.1346e-01, -6.2669e-01, -1.2793e+00,\n",
       "         -8.4220e-01,  1.9835e+00,  3.2300e-01, -4.8436e-01,  6.8796e-01,\n",
       "         -9.6357e-01, -2.4206e-03,  5.0504e-01,  3.6160e-01, -1.4912e+00,\n",
       "          7.2748e-01,  6.2135e-01, -1.0252e+00, -1.0879e-01,  3.7512e-01,\n",
       "          3.7233e-01,  1.3271e+00,  3.0472e-01,  5.9775e-01,  1.8262e+00,\n",
       "          2.0299e-01, -1.8578e+00, -6.9206e-01, -2.8668e+00,  5.1299e-01,\n",
       "         -7.2065e-01, -5.9004e-02, -4.9856e-01, -1.8042e+00, -4.4336e-01,\n",
       "          2.3290e-01,  7.3007e-01, -2.6354e-01, -7.5752e-01, -2.0772e-01,\n",
       "          1.0140e+00,  3.9440e-01, -8.0137e-01,  9.1391e-01, -4.6939e-01,\n",
       "          6.9337e-01,  2.0409e+00,  1.4016e+00,  3.6985e-01, -1.8277e+00,\n",
       "         -1.8367e+00, -1.2283e+00, -5.3258e-01, -1.3341e+00, -7.0493e-01,\n",
       "          1.5719e+00,  6.9197e-01, -1.1990e+00, -7.0298e-01,  1.8940e+00,\n",
       "          4.5657e-01, -2.3932e-01,  5.8249e-01, -1.2776e-01,  1.5865e+00,\n",
       "          9.8647e-01, -3.5740e-01, -9.1028e-01, -6.2443e-01,  1.1063e+00,\n",
       "          2.1861e-01,  8.3622e-02, -2.3446e+00, -3.7098e-01, -2.0061e+00,\n",
       "         -1.3931e+00,  1.7914e+00,  2.3281e+00,  6.8271e-01, -1.1446e+00,\n",
       "         -7.7877e-01,  9.3594e-01, -7.6493e-02, -7.1018e-01,  9.4961e-01,\n",
       "          4.0361e-01,  1.4954e+00, -1.0191e+00, -1.8189e-01, -3.2145e-01,\n",
       "          5.6345e-01, -2.7815e-01, -3.2488e-01,  1.7077e+00,  1.8012e+00,\n",
       "          7.0720e-01, -2.5495e+00,  9.5914e-01,  2.3488e+00,  1.3907e-01,\n",
       "         -5.4410e-01, -8.9470e-01,  1.3851e+00, -2.9070e-02, -1.5526e-01,\n",
       "         -2.5942e-01, -1.0981e+00, -1.1662e+00, -2.7688e-02, -1.2725e+00,\n",
       "         -2.5158e-01,  3.2276e-01, -1.3490e+00, -7.9506e-01,  3.7434e-01,\n",
       "          9.4814e-01, -1.5814e+00,  7.3492e-01, -2.7960e-01, -1.2373e+00,\n",
       "          9.6350e-01,  1.2528e-01, -1.0915e+00,  1.9046e+00, -5.0179e-01,\n",
       "          6.9615e-01,  5.7722e-01,  4.1392e-01, -6.1373e-01, -1.3667e+00,\n",
       "         -1.6330e+00, -3.0086e-01,  7.9057e-01,  1.0343e+00,  1.1878e+00,\n",
       "          1.4152e+00,  4.6653e-01,  3.4637e-01, -8.1978e-02,  8.9125e-01,\n",
       "          6.3550e-01,  1.4545e+00, -6.8070e-01, -8.1530e-01,  4.1594e-01,\n",
       "         -1.5705e+00,  9.5053e-02,  1.0035e+00,  1.8717e+00, -2.0429e+00,\n",
       "         -6.0637e-01, -1.2244e+00, -1.5254e+00, -2.4731e-01, -8.1683e-01,\n",
       "         -1.4937e+00, -3.6437e-01, -6.0096e-01, -3.8204e-01, -1.5641e+00,\n",
       "         -6.2839e-01, -9.8342e-01, -6.6754e-01, -1.3931e+00,  2.5929e-01,\n",
       "          2.0348e+00, -1.1891e+00,  1.5074e+00,  1.3185e+00,  7.4621e-01,\n",
       "          1.1487e+00, -2.7539e+00,  3.4432e-01,  2.9929e-01,  3.1502e-01,\n",
       "          1.7778e-01, -2.0291e+00, -1.3243e+00, -1.7521e+00, -1.1256e+00,\n",
       "         -3.9506e-01,  8.1216e-01, -1.9420e-01,  2.7066e-01, -1.1886e+00,\n",
       "         -1.6722e+00,  1.2663e+00, -5.7828e-01, -1.7667e-01,  1.8177e-01,\n",
       "          1.7716e+00,  1.3042e+00,  1.1875e-02, -4.4522e-02, -6.4007e-01,\n",
       "         -7.5213e-01,  8.8867e-01,  1.1015e-01,  2.4723e-01, -4.9504e-01,\n",
       "          8.2497e-02, -3.8672e-02, -1.6652e+00,  1.0433e+00, -2.8058e-01,\n",
       "         -1.2157e+00, -5.3055e-01,  7.4705e-01, -1.5322e+00,  4.4034e-01,\n",
       "          1.6289e-01, -1.5175e+00, -1.2268e+00,  5.5686e-01, -5.5143e-01,\n",
       "         -1.1629e+00, -1.6041e-01, -1.2805e+00,  2.1185e-01, -8.0510e-01,\n",
       "          6.2278e-01, -1.0603e+00, -6.4021e-01, -3.0222e-01, -8.6358e-03,\n",
       "          1.5897e-01,  9.4215e-01,  1.4532e-01,  1.4751e+00, -8.1121e-01,\n",
       "          1.1679e+00, -9.0004e-01, -5.1191e-01, -3.8504e-01,  1.1922e+00,\n",
       "          3.4340e-01,  1.5501e+00,  1.0394e+00, -7.5211e-01,  2.7991e-01,\n",
       "         -1.3111e+00, -1.1898e+00,  1.4371e+00, -1.6683e+00,  1.1583e+00,\n",
       "         -1.7433e+00, -3.1085e-01, -2.8327e-01, -1.8420e+00,  4.7387e-01,\n",
       "          5.3180e-01,  1.1704e+00,  1.8943e+00, -1.2912e+00, -2.8047e-01,\n",
       "          3.9357e-01, -4.5554e-02,  1.1095e+00, -1.7421e+00,  7.4785e-01,\n",
       "         -5.0501e-02,  1.6810e+00,  2.0955e-01, -1.0512e+00, -1.0675e+00,\n",
       "         -6.8189e-01,  1.1740e+00, -9.2466e-02,  2.6358e-01, -1.5509e+00,\n",
       "          1.2009e+00, -1.5512e+00, -1.5386e-01,  1.0178e+00,  1.3897e+00,\n",
       "          4.5482e-01,  1.1046e+00,  7.7051e-01, -1.2806e+00, -1.4468e-01,\n",
       "         -1.0896e+00, -4.1448e-01, -5.1062e-02, -1.3210e+00, -3.9791e-01,\n",
       "          1.0949e+00, -3.4114e-01,  9.4891e-01,  1.8980e-01,  3.3524e-01,\n",
       "          1.2717e-01,  1.1203e+00,  1.1458e+00,  1.1575e+00, -7.1031e-01,\n",
       "          8.5018e-01,  6.1190e-01,  9.9399e-01, -1.9855e-02,  1.1847e+00,\n",
       "          9.5236e-01,  1.8364e+00, -7.2295e-02,  2.1473e-01,  1.5467e+00,\n",
       "          5.5716e-01,  6.7598e-01,  7.6644e-01,  4.1165e-01,  5.1784e-01,\n",
       "          4.1887e-01,  2.3917e-01,  6.9945e-01, -1.0837e+00, -3.2516e-02,\n",
       "         -8.1570e-01, -2.4126e-01,  5.0484e-02,  9.0066e-01, -1.1453e+00,\n",
       "          3.7503e-03,  9.0599e-02, -6.5065e-01,  4.3499e-01, -1.6942e+00,\n",
       "          1.6383e+00,  5.2196e-01, -9.2120e-01,  5.7118e-02,  7.2180e-01,\n",
       "         -8.2237e-01, -6.5938e-01, -3.3702e-01, -9.7512e-01,  6.5080e-01,\n",
       "          3.3319e-02, -9.7250e-02,  1.7479e+00, -6.5949e-01, -1.8204e+00,\n",
       "         -1.3966e+00, -4.7329e-01, -1.8089e+00,  1.4827e-01, -7.6630e-01,\n",
       "         -7.4455e-01, -2.7844e-01, -1.0345e-01,  1.1902e+00,  1.0397e+00,\n",
       "          9.7588e-01,  1.7663e+00,  6.3383e-02,  5.5751e-01, -9.5282e-01,\n",
       "          1.3942e+00,  4.4011e-01, -1.1798e+00,  9.2892e-01, -8.8990e-01,\n",
       "          5.7365e-01, -1.8071e+00, -8.5367e-01,  7.9673e-01,  8.5841e-01,\n",
       "         -1.6232e-01, -8.0293e-01, -1.7772e-01, -1.5710e+00,  1.2708e+00,\n",
       "         -9.2946e-01, -1.4231e+00,  4.2106e-01, -2.7937e-01,  4.3144e-01,\n",
       "         -5.6305e-01,  7.0787e-01, -2.0074e+00, -1.1491e+00,  8.6701e-01,\n",
       "          1.2784e-02,  1.2462e+00,  1.2825e-01, -1.2424e+00, -1.1870e+00,\n",
       "         -7.8788e-01,  8.2516e-01, -9.2886e-01,  3.6219e-01, -3.1898e-01,\n",
       "         -4.4875e-01,  9.9268e-01, -8.7450e-01,  6.1800e-01,  3.2574e-01,\n",
       "         -9.0850e-01,  3.5925e-01, -7.6024e-01, -2.0969e-01, -5.9497e-02,\n",
       "         -6.4043e-02, -9.3003e-01, -1.5107e+00,  7.0049e-01, -1.5472e+00,\n",
       "         -3.3319e-02, -7.0698e-01, -3.5513e-01, -1.5520e+00, -2.2141e-01,\n",
       "         -6.2778e-01,  1.1764e+00,  1.7599e+00, -1.5234e+00, -9.4723e-01,\n",
       "          1.8190e+00,  3.8617e-01, -1.6972e-01,  1.0817e+00, -1.0321e+00,\n",
       "          5.0397e-01, -9.0895e-02, -8.9832e-01, -1.0406e+00, -6.4772e-01,\n",
       "          5.9377e-01, -1.3091e+00, -6.8954e-01,  4.8769e-01,  3.4478e-01,\n",
       "          8.8440e-01, -8.5696e-02,  1.1098e+00,  6.4232e-01, -1.9673e+00,\n",
       "          7.5225e-01, -5.3944e-01, -6.5500e-01, -9.4798e-01, -5.1063e-01,\n",
       "         -7.4553e-01, -1.7459e-01,  2.3334e-01,  6.6599e-01,  3.3487e-01,\n",
       "         -1.0997e+00, -1.5616e-01,  1.7748e-01,  1.3809e+00, -5.7252e-01,\n",
       "         -4.0705e-01, -2.5654e-01,  9.5714e-01,  7.2941e-01,  7.8688e-01,\n",
       "         -6.3745e-02,  3.6418e-01, -4.9420e-01, -1.3408e+00,  1.2598e+00,\n",
       "          1.1867e+00, -1.4160e+00, -7.9907e-01,  2.1877e-02,  4.2253e-01,\n",
       "         -5.2442e-03, -4.2319e-01, -1.4709e+00,  1.3806e+00,  9.4086e-01,\n",
       "          1.1731e+00,  1.1642e+00,  1.0952e+00,  2.2955e+00, -1.2389e+00,\n",
       "          1.7448e-01,  8.0879e-01, -3.9079e-01, -4.8679e-01,  7.5492e-02,\n",
       "         -6.9612e-01,  1.6921e+00, -1.0125e+00,  8.4714e-01, -1.9012e+00,\n",
       "         -1.0513e+00, -3.3220e-01,  2.4339e+00,  3.0303e-02,  4.0663e-01,\n",
       "         -7.6451e-01,  8.5294e-01, -4.9768e-01, -5.5658e-01,  7.6094e-01,\n",
       "         -5.8173e-01,  9.0224e-01,  1.5372e+00,  2.8638e-01, -1.9205e+00,\n",
       "          6.2206e-01, -1.2779e+00, -7.0465e-02,  1.5094e-01,  7.1491e-01,\n",
       "          4.6394e-02,  3.5407e-02, -1.1806e+00, -1.4609e-01,  3.3230e-01,\n",
       "          2.5286e+00, -6.9055e-01, -4.8704e-01,  1.9184e+00,  6.8924e-01,\n",
       "          1.2680e+00, -5.4105e-01, -1.4190e+00,  3.6607e-01,  1.4052e+00,\n",
       "         -1.5604e+00,  8.1748e-01,  9.5061e-01, -2.1761e-01, -2.4206e+00,\n",
       "         -3.5626e-01,  3.1157e-01,  3.7280e-01, -5.4104e-01,  1.0763e-01,\n",
       "          1.7820e+00,  1.4501e+00,  3.8304e-01, -2.6301e-01, -4.0334e-01,\n",
       "         -3.2945e-01, -1.5350e+00, -1.2123e+00, -1.8777e+00, -4.8131e-01,\n",
       "          6.2518e-03, -4.7706e-01, -1.8206e+00, -1.0937e+00, -4.9935e-01,\n",
       "         -7.6817e-01, -1.3712e-01, -9.4836e-01, -3.1244e-01,  4.0949e-01,\n",
       "         -6.4491e-01, -1.6360e-01,  4.0520e-01, -1.1281e+00, -1.6036e-02,\n",
       "          1.3668e-01, -9.8008e-01, -5.7097e-01, -9.7608e-02,  1.0645e+00,\n",
       "          9.2592e-01, -1.0177e+00, -2.5506e-01, -1.6321e-01,  2.4980e+00,\n",
       "         -1.2721e+00, -7.7352e-01,  1.4399e+00,  1.0048e+00,  1.8716e+00,\n",
       "         -2.5267e-01, -1.0189e+00,  1.1952e+00,  1.7756e+00, -6.1763e-01,\n",
       "          1.7504e+00, -1.2268e+00, -1.2024e+00]], grad_fn=<SliceBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\"Siapa nama tokoh utama dalam serial SLAMDunk?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3, 6186, 1769, 2991, 2191, 1570, 3301, 10404, 9509, 1010, 1028, 32, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
